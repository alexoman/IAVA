{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab03_2022_working.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f7d306a4693f4d4891688641a130cf52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fd1154a6ad9a41db9b4627bc78a2ad4c",
              "IPY_MODEL_1d230943327b4d629962d0bf5b9b827d",
              "IPY_MODEL_1f92671521ca45feab1d0646db20884a"
            ],
            "layout": "IPY_MODEL_853208d6bf404affa78db3d99017523f"
          }
        },
        "fd1154a6ad9a41db9b4627bc78a2ad4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f59b1347f4dd4673a6ac6587eb15cbfb",
            "placeholder": "​",
            "style": "IPY_MODEL_cb27c2a636474369b5cc62960cdfd567",
            "value": ""
          }
        },
        "1d230943327b4d629962d0bf5b9b827d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab7ac233f671426aa4a885bc3f0d0cc0",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_99002727c234454082a2242910843c14",
            "value": 170498071
          }
        },
        "1f92671521ca45feab1d0646db20884a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11744ac6b54b48e688f7665cfc957012",
            "placeholder": "​",
            "style": "IPY_MODEL_add02fcd51614bc393534cd8ba9ef384",
            "value": " 170499072/? [00:11&lt;00:00, 16253512.02it/s]"
          }
        },
        "853208d6bf404affa78db3d99017523f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f59b1347f4dd4673a6ac6587eb15cbfb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb27c2a636474369b5cc62960cdfd567": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab7ac233f671426aa4a885bc3f0d0cc0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99002727c234454082a2242910843c14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "11744ac6b54b48e688f7665cfc957012": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "add02fcd51614bc393534cd8ba9ef384": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexoman/IAVA/blob/main/Lab03_2022_working.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpoTZudv_LK5"
      },
      "source": [
        "## Straturi Noi\n",
        "\n",
        "In continuare o sa utilizam o parte din straturile prezentate in curs.\n",
        "\n",
        "Staturi noi:\n",
        "\n",
        "Strat Convolutional:\n",
        "* torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0)\n",
        "\n",
        "Strat de Pooling:\n",
        "* torch.nn.MaxPool2d(kernel_size, stride=None, padding=0)\n",
        "* torch.nn.AveragePool2d(kernel_size, stride=None, padding=0)\n",
        "\n",
        "Strat de Adaptive Pool, intalnit adesea si ca Global Pool:\n",
        "* torch.nn.AdaptiveAvgPool2d(output_size)\n",
        "* torch.nn.AdaptiveMaxPool2d(output_size)\n",
        "\n",
        "Strat de liniarizare:\n",
        "\n",
        "* torch.nn.Flatten()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HWqK9mqHxgB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c0cf195-dad2-4ac7-f134-293c229f7c1a"
      },
      "source": [
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "dummy_input_tensor = torch.rand((1,3,100,100))  # Input random de marime 100x100 cu 3 canale\n",
        "\n",
        "layer = nn.Conv2d(in_channels=3, out_channels=10, kernel_size=(3,3), stride=(2,2))\n",
        "print(\"Conv1 result shape\",layer(dummy_input_tensor).shape)\n",
        "\n",
        "layer = nn.Conv2d(in_channels=3, out_channels=10, kernel_size=(13,13), stride=(2,2))\n",
        "print(\"Conv2 result shape\",layer(dummy_input_tensor).shape)\n",
        "\n",
        "layer = nn.MaxPool2d(kernel_size=(3,3)) # Stride este inferat din kernel size, ca fiind egal cu kernel size ca sa nu repete elementele luate\n",
        "print(\"Pool result shape\",layer(dummy_input_tensor).shape)\n",
        "\n",
        "# Utilizat pentru a reduce dimensiunea input-ului la una prestabilita, util cand marimea input-ului este variabil\n",
        "layer = nn.AdaptiveAvgPool2d(output_size=(5,5))\n",
        "print(\"Global Pool result shape\",layer(dummy_input_tensor).shape)\n",
        "\n",
        "layer = nn.Flatten()\n",
        "print(\"Flaten result shape\",layer(dummy_input_tensor).shape)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conv1 result shape torch.Size([1, 10, 49, 49])\n",
            "Conv2 result shape torch.Size([1, 10, 44, 44])\n",
            "Pool result shape torch.Size([1, 3, 33, 33])\n",
            "Global Pool result shape torch.Size([1, 3, 5, 5])\n",
            "Flaten result shape torch.Size([1, 30000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOTmqyCxJ3fk"
      },
      "source": [
        "###Cerinte\n",
        "\n",
        "**(1p)** Utilizati o serie de Conv2D/Pool2D pentru a ajunge la urmatoarele marimi plecand de la input 3x100x100:\n",
        "*   [1, 10, 25, 25] # hint: folositi stride si padding\n",
        "*   [1, 10, 32, 32]\n",
        "*   [1, 3, 2, 2]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HtEeXbeKeKu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee5af6dc-2f72-4c08-c2cc-cebd469ead48"
      },
      "source": [
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "dummy_input_tensor = torch.rand((1,3,100,100))  # Input random de marime 100x100 cu 3 canale\n",
        "\n",
        "### Completati codul pentru cerinta aici\n",
        "layer1 = nn.Conv2d(in_channels=3, out_channels=10, kernel_size=(8,8), stride=(4,4), padding=(3,3))\n",
        "print(\"Conv2 result shape\",layer1(dummy_input_tensor).shape)\n",
        "print()\n",
        "layer2 = nn.Conv2d(in_channels=3, out_channels=10, kernel_size=(10,10), stride=(3,3), padding=(2,2))\n",
        "print(\"Con2 result shape\",layer2(dummy_input_tensor).shape)\n",
        "print()\n",
        "layer3 = nn.Conv2d(in_channels=3, out_channels=3, kernel_size=(10,10), stride=(50,50))\n",
        "print(\"Conv2 result shape\",layer3(dummy_input_tensor).shape)\n",
        "\n",
        "layer4 = nn.MaxPool2d(kernel_size=(4,4)) # Stride este inferat din kernel size, ca fiind egal cu kernel size ca sa nu repete elementele luate\n",
        "print(\"Pool result shape\",layer4(dummy_input_tensor).shape)\n",
        "\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conv2 result shape torch.Size([1, 10, 25, 25])\n",
            "\n",
            "Con2 result shape torch.Size([1, 10, 32, 32])\n",
            "\n",
            "Conv2 result shape torch.Size([1, 3, 2, 2])\n",
            "Pool result shape torch.Size([1, 3, 25, 25])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvdPtetggm61"
      },
      "source": [
        "## Instantierea seturilor de date"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czyIhYt5gmUQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "f7d306a4693f4d4891688641a130cf52",
            "fd1154a6ad9a41db9b4627bc78a2ad4c",
            "1d230943327b4d629962d0bf5b9b827d",
            "1f92671521ca45feab1d0646db20884a",
            "853208d6bf404affa78db3d99017523f",
            "f59b1347f4dd4673a6ac6587eb15cbfb",
            "cb27c2a636474369b5cc62960cdfd567",
            "ab7ac233f671426aa4a885bc3f0d0cc0",
            "99002727c234454082a2242910843c14",
            "11744ac6b54b48e688f7665cfc957012",
            "add02fcd51614bc393534cd8ba9ef384"
          ]
        },
        "outputId": "e67aca3e-e8b4-494e-b7a3-de98a5bd228d"
      },
      "source": [
        "import torchvision\n",
        "\n",
        "cifar_train = torchvision.datasets.CIFAR10(\"./data\", download=True)\n",
        "cifar_test = torchvision.datasets.CIFAR10(\"./data\", train=False)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f7d306a4693f4d4891688641a130cf52"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOA4ted_hHdB"
      },
      "source": [
        "## Crearea Dataloader-ului\n",
        "\n",
        "### Cerinte\n",
        " * **(2p)** Implementati functia de preprocesare a datelor, __collate_fn(examples)__.\n",
        "\n",
        "\n",
        "Atentie! Spre deosebire de intrarea pentru retelele fully-connected, pentru retelele convolutionale intrearea nu trebuie liniarizata, ci doar normalizata.\n",
        "\n",
        "#### Hint\n",
        "\n",
        "  * Amintiti-va folosirea functiei __normalize__ din torchvision.transforms.functional din laboratorul trecut.\n",
        "  * Modificati functia *collate_fn* din laboratorul trecut, pentru a normaliza datele in intervalul [-1, 1]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGHfd229hRyR"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms.functional import to_tensor, normalize\n",
        "\n",
        "def collate_fn(examples):\n",
        "  ### Completati codul pentru cerinta aici\n",
        "  processed_images = []\n",
        "  processed_labels = []\n",
        "\n",
        "  for example in examples:\n",
        "    tensor_image = to_tensor(example[0])\n",
        "    normalized_tensor_image = normalize(tensor_image, [0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
        "    normalized_tensor_image = normalized_tensor_image.unsqueeze(0)\n",
        "    processed_images.append(normalized_tensor_image)\n",
        "    \n",
        "    label = np.array(example[1])\n",
        "    tensor_label = torch.tensor(label)\n",
        "    tensor_label = tensor_label.unsqueeze(0)\n",
        "    processed_labels.append(tensor_label)\n",
        "\n",
        "  torch_images = torch.cat(processed_images, dim=0)\n",
        "  torch_labels = torch.cat(processed_labels, dim=0)\n",
        "  \n",
        "  return torch_images, torch_labels\n",
        "\n",
        "batch_size=500\n",
        "train_loader = DataLoader(cifar_train, batch_size=500, shuffle=True, num_workers=2, collate_fn=collate_fn)\n",
        "test_loader = DataLoader(cifar_test, batch_size=1, shuffle=False, collate_fn=collate_fn)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnV6PIC1kQMi"
      },
      "source": [
        "## Crearea unei retele neurale convolutionale\n",
        "\n",
        "### Cerinte\n",
        " * **(1p)** Creati o clasa care mosteneste clasa nn.Module. Ea va reprezenta o retea neurala convolutionala pentru clasificare ale celor 10 clase din datasetul CIFAR10.\n",
        "    * Reteaua trebuie sa aiba 2 straturi convolutionale care sa reduca dimensiunea spatiala a imaginii\n",
        "    * Liniarizati iesirea celui de-al doilea strat convolutional\n",
        "    * Adaugat stratul final de tipul 'fully-connected'\n",
        "    * Folositi o functie de activare la alegere\n",
        "\n",
        "#### Hint\n",
        "\n",
        "Pentru a liniariza iesirea din cel de-al doilea feature map puteti adopta mai multe strategii:\n",
        "  * Liniarizare prin schimbarea shape-ului la [batch_size, -1]\n",
        "  * Global Max Pooling si apoi liniarizare la [batch_size, -1]\n",
        "  * Average Max Pooling si apoi liniarizare la [batch_size, -1]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1Ddc7D-lAEN"
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net,self).__init__()\n",
        "    ### Completati codul pentru cerinta aici\n",
        "    self.layer1 = nn.Conv2d(in_channels=3, out_channels=10, kernel_size=(3,3), stride=(2,2))\n",
        "    self.layer2 = nn.Conv2d(in_channels=10, out_channels=5, kernel_size=(3,3), stride=(2,2))\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.linear = nn.Linear(245,10)\n",
        "    self.activation = nn.ReLU()\n",
        "\n",
        "  def forward(self,x):\n",
        "    ### Completati codul pentru cerinta aici\n",
        "    output_layer1 = self.layer1(x)\n",
        "    output1 = self.activation(output_layer1)\n",
        "    output_layer2 = self.layer2(output1)\n",
        "    output2 = self.flatten(output_layer2)\n",
        "    output2 = self.activation(output2)\n",
        "    output_linear = self.linear(output2)\n",
        "    output = self.activation(output_linear)\n",
        "    return output"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wK0Z9NeYTghv"
      },
      "source": [
        "## Definirea obiectelor folosite in timpul antrenarii\n",
        "\n",
        "### Cerinte **(1p)**\n",
        "  * Initializati numarul de epoci\n",
        "  * Initializati retea\n",
        "  * Initializati optimizator\n",
        "  * Initializati functia de cost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Az3WKQdpod34"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Definiti numarul de epoci\n",
        "epochs = 5\n",
        "\n",
        "# Definiti reteaua\n",
        "network = Net()\n",
        "\n",
        "# Definiti optimizatorul\n",
        "optimizer = optim.SGD(network.parameters(), lr=1e-2,momentum=0.8)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Dupa definirea optimizatorului si dupa fiecare iteratie de antrenare, trebuie \n",
        "apelata functia zero_grad() pentru a seta valoare tuturor gradientilor la zero.\n",
        "\"\"\"\n",
        "# Completati aici codul pentru seta valoare tuturor gradientilor la zero\n",
        "optimizer.zero_grad()\n",
        "\n",
        "# Definiti functia cost pentru clasificare Cross-Entropy\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAnUsWYWodb4"
      },
      "source": [
        "## Definirea functiei de antrenare"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9MTYanoMZ8H"
      },
      "source": [
        "def test_acc(net: nn.Module, test_loader: DataLoader):\n",
        "  net.eval()\n",
        "\n",
        "  total = 0\n",
        "  correct = 0\n",
        "\n",
        "  for test_images, test_labels in test_loader:\n",
        "    total += len(test_images)\n",
        "    out_class = torch.argmax(net(test_images))\n",
        "    correct += torch.sum(out_class == test_labels)\n",
        "\n",
        "  return correct / total * 100\n",
        "\n",
        "\n",
        "def train_fn(epochs: int, train_loader: DataLoader, test_loader: DataLoader, \n",
        "             net: nn.Module, loss_fn: nn.Module, optimizer: optim.Optimizer):\n",
        "  # Iteram prin numarul de epoci\n",
        "  for e in range(epochs):\n",
        "    net.train()\n",
        "\n",
        "    # Iteram prin fiecare batch din dataloader\n",
        "    for images, labels in train_loader:\n",
        "      # Aplicam reteaua neurala pe imaginile din batch-ul curent\n",
        "      out = net(images)\n",
        "      # Aplicam functia cost pe iesirea retelei neurale si pe etichetele imaginilor \n",
        "      loss = loss_fn(out, labels)\n",
        "      # Aplicam algoritmul de back-propagation\n",
        "      loss.backward()\n",
        "      # Facem pasul de optimizare, pentru a actualiza parametrii retelei\n",
        "      optimizer.step()\n",
        "      # Apelam functia zero_grad() pentru a uita gradientii de la iteratie curenta\n",
        "      optimizer.zero_grad()\n",
        "    \n",
        "    print(\"Loss-ul la finalul epocii {} are valoarea {}\".format(e, loss.item()))\n",
        "\n",
        "    # Calculam acuratetea\n",
        "    acc = test_acc(net, test_loader)\n",
        "    print(\"Acuratetea la finalul epocii {} este {:.2f}%\".format(e + 1, acc))"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWvb00A-TkJq"
      },
      "source": [
        "\n",
        "## Antrenarea\n",
        "\n",
        "### Cerinte\n",
        "  * Antrenati reteaua definita mai sus (clasa Net)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqUwOWmDMpqQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d341263-5280-47ca-eaf0-37259a4a8bef"
      },
      "source": [
        "train_fn(epochs, train_loader, test_loader, network, loss_fn, optimizer)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss-ul la finalul epocii 0 are valoarea 2.2944154739379883\n",
            "Acuratetea la finalul epocii 1 este 14.77%\n",
            "Loss-ul la finalul epocii 1 are valoarea 2.224931478500366\n",
            "Acuratetea la finalul epocii 2 este 19.53%\n",
            "Loss-ul la finalul epocii 2 are valoarea 2.075087308883667\n",
            "Acuratetea la finalul epocii 3 este 28.11%\n",
            "Loss-ul la finalul epocii 3 are valoarea 2.0219709873199463\n",
            "Acuratetea la finalul epocii 4 este 32.37%\n",
            "Loss-ul la finalul epocii 4 are valoarea 1.9153759479522705\n",
            "Acuratetea la finalul epocii 5 este 34.28%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmVavwztTZkz"
      },
      "source": [
        "## Reteaua LeNet\n",
        "\n",
        "### Cerinte\n",
        "  * **(2.5p)** Implementati reteaua LeNet dupa figura de mai jos si antrenati-o\n",
        "\n",
        "\n",
        "![alt text](https://drive.google.com/uc?id=1OVancUyIViMRMZdULFSVCvXJHQP0NGUV)\n",
        "\n",
        "Figura arhitectura LeNet\n",
        "\n",
        "![alt text](https://debuggercafe.com/wp-content/uploads/2019/07/Layers-in-LeNet.png)\n",
        "\n",
        "Tabel arhitectura LeNet\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoe1vbggO-4U"
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class LeNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(LeNet,self).__init__()\n",
        "    ### Completati codul pentru cerinta aici\n",
        "    self.layer1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=(5,5), stride=(1,1))\n",
        "    self.activation = nn.ReLU()# nn.GELU()\n",
        "    self.avgPool1 = nn.AvgPool2d(kernel_size = (2,2), stride=(2,2), padding=0)\n",
        "    self.layer2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=(5,5), stride=(1,1))\n",
        "    # self.avgPool2 = nn.AveragePool2d(kernel_size = (2,2), stride=(2,2), padding=0)\n",
        "    self.layer3 = nn.Conv2d(in_channels=16, out_channels=120, kernel_size=(5,5), stride=(1,1))\n",
        "    self.linear = nn.Linear(120,84)\n",
        "    self.linear2 = nn.Linear(84,10)\n",
        "    self.softmax = nn.Softmax(dim = 1)\n",
        "    self.flatten = nn.Flatten()\n",
        "    #self.norm1 = nn.BatchNorm2d(6)\n",
        "\n",
        "  def forward(self,x):\n",
        "    ### Completati codul pentru cerinta aici\n",
        "    output_layer1 = self.layer1(x)\n",
        "    output1 = self.activation(output_layer1)\n",
        "    output_avgPool1 = self.avgPool1(output1)\n",
        "    output2 = self.activation(output_avgPool1)\n",
        "    #output2 = self.norm1(output2)\n",
        "    output_layer2 = self.layer2(output2)\n",
        "    output3 = self.activation(output_layer2)\n",
        "    output_avgPool1 = self.avgPool1(output3)\n",
        "    output4 = self.activation(output_avgPool1)\n",
        "    \n",
        "    output_layer3 = self.layer3(output4)\n",
        "    output5 = self.activation(output_layer3)\n",
        "    output5 = self.flatten(output5)\n",
        "    output_linear = self.linear(output5)\n",
        "    output6 = self.activation(output_linear)\n",
        "    output_linear2 = self.linear2(output6)\n",
        "    output7 = self.softmax(output_linear2)\n",
        "\n",
        "    return output7"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0XPmGrEol9M"
      },
      "source": [
        "## Redefinirea obiectelor folosite in timpul antrenarii pentru reteaua LeNet\n",
        "\n",
        "### Cerinta\n",
        " * **(0.5p)** Redefiniti obiectele necesare pentru a antrena reteaua LeNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhqNoDmQo66c"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Definiti numarul de epoci\n",
        "epochs = 8\n",
        "\n",
        "# Definiti reteaua\n",
        "lenet = LeNet().cuda()\n",
        "\n",
        "# Definiti optimizatorul\n",
        "lenet_optimizer = optim.Adam(lenet.parameters(), lr=1e-3)\n",
        "\n",
        "# Completati aici codul pentru a face gradientii zero\n",
        "lenet_optimizer.zero_grad()\n",
        "\n",
        "# Definiti functia cost pentru clasificare Cross-Entropy\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwIQwUQpo_eR"
      },
      "source": [
        "## Antrenarea retelei LeNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUl8W42do_sL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "outputId": "b29119cd-0cf0-4911-ee3f-3aec4c41334f"
      },
      "source": [
        "train_fn(epochs, train_loader, test_loader, lenet, loss_fn, lenet_optimizer)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-c407559d6558>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlenet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlenet_optimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'train_fn' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OspDtfFnTodr"
      },
      "source": [
        "###Augmentare retea\n",
        "\n",
        "Reteaua de mai devreme duce lipsa de regularizare. O forma foarte puternica de regularizare este normalizarea, iar pentru acest lucru exista straturi speciale.\n",
        "\n",
        "Astfel de straturi:\n",
        "\n",
        "* torch.nn.BatchNorm2d(num_features)\n",
        "* torch.nn.InstanceNorm2d(num_features)\n",
        "\n",
        "Un alt element important il reprezinta functiile de activare, care pot influenta convergenta si puterea retelei. Cateva exemple de functii de activate:\n",
        "\n",
        "\n",
        "* Relu\n",
        "* Sigmoid\n",
        "* Tanh\n",
        "* LeakyRelu\n",
        "* GELU\n",
        "\n",
        "## Cerinta\n",
        "\n",
        "**(2p)** Experimentati cu augmentarile mentionate mai sus in cadrul ultimei retele definite pentru a obtine o acuratete mai buna. Observati viteza de convergenta si performanta retelei pentru 3 configuratii diferite.\n",
        "\n",
        "\n",
        "###Bonus\n",
        "**(1p)** Antrenati reteaua folosind GPU (Graphics processing unit)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  \n"
      ]
    }
  ]
}